{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bazziamir24/OpenAI_API_Setup_Demo/blob/main/OpenAI_API_Setup_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API"
      ],
      "metadata": {
        "id": "B7SoxfO8pvlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) How to get started"
      ],
      "metadata": {
        "id": "178fYnvhYp4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://platform.openai.com/docs/api-reference\n",
        "\n",
        "Create OpenAI account & sign in\n",
        "\n",
        "Once you're in, go to https://platform.openai.com/ & generate API Key in the API Keys tab\n",
        "\n",
        "Once you're all set, run `pip install openai` in your terminal"
      ],
      "metadata": {
        "id": "ouiG6zpBYu_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WcUNl7bbNoD",
        "outputId": "80776b38-1ebb-46c5-83d0-a2f32fd3a822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.5-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) The Basics"
      ],
      "metadata": {
        "id": "LiQXKOQJaTii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use 'chatgpt' in your projects, you're actually using what openai call 'Chat Completions'. This is what your typical usage of openai's chat completions looks like:"
      ],
      "metadata": {
        "id": "gX0Hewznasne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY8j3JZfptmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "b7612f05-a8e9-4fa6-b102-2e78c86ecc0d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-47193dd13e4b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m response = client.chat.completions.create(\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "client.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\", # the model of gpt you're using\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an AI engineer tasked with explaining concepts of artificial intelligence clearly and concisely.\"}, # system messages are usually the instructions you feed into GPT\n",
        "    {\"role\": \"user\", \"content\": \"Can you explain the difference between supervised and unsupervised learning in AI?\"} # this would be the question for instance one of your users asks\n",
        "  ]\n",
        "  # optional: you can also control temperature. Definition from the OpenAI Docs: Lower values for temperature result in more consistent outputs (e.g. 0.2), while higher values generate more diverse and creative results (e.g. 1.0). Select a temperature value based on the desired trade-off between coherence and creativity for your specific application. The temperature can range is from 0 to 2.\n",
        ")\n",
        "\n",
        "print(response)\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if you run the above with a valid API key, as you can see I'm printing for you 2 different things: `response`, and `response.choices[0].message.content`, and this is what both would look like as a result:"
      ],
      "metadata": {
        "id": "5TCO7hA4pxVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is `response`:**\n",
        "\n",
        "{\n",
        "  \"choices\": [\n",
        "    {\n",
        "      \"finish_reason\": \"stop\",\n",
        "      \"index\": 0,\n",
        "      \"message\": {\n",
        "        \"content\": \"Sure! In artificial intelligence, supervised and unsupervised learning are two primary types of machine learning.\n",
        "\n",
        "**Supervised Learning:** In supervised learning, the AI model is trained on a labeled dataset, which means that each training example is paired with an output label. The model learns to make predictions or decisions based on this labeled data. Examples include classification (e.g., identifying whether an email is spam or not) and regression (e.g., predicting house prices). The key aspect is that the model is given explicit instructions on what the output should be for each input during training.\n",
        "\n",
        "**Unsupervised Learning:** In unsupervised learning, the AI model is trained on data that does not have labeled responses. Instead, the model tries to find patterns and relationships in the data on its own. Common techniques include clustering (e.g., grouping customers based on purchasing behavior) and association (e.g., finding products that are frequently bought together). The model explores the data and looks for structures or patterns without any predefined labels or outcomes.\n",
        "\n",
        "In summary, supervised learning uses labeled data to train models to make predictions or decisions, while unsupervised learning deals with unlabeled data to identify hidden patterns and relationships.\"\n",
        "        ,\n",
        "        \"role\": \"assistant\"\n",
        "      },\n",
        "      \"logprobs\": null\n",
        "    }\n",
        "  ],\n",
        "  \"created\": 1677664795,\n",
        "  \"id\": \"chatcmpl-7QyqpwdfhqwajicIEznoc6Q47XAyW\",\n",
        "  \"model\": \"gpt-4o\",\n",
        "  \"object\": \"chat.completion\",\n",
        "  \"usage\": {\n",
        "    \"completion_tokens\": 190,\n",
        "    \"prompt_tokens\": 57,\n",
        "    \"total_tokens\": 247\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "4LmyVvM2c_a3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is `response.choices[0].message.content`:**\n",
        "\n",
        "Sure! In artificial intelligence, supervised and unsupervised learning are two primary types of machine learning.\n",
        "\n",
        "**Supervised Learning:** In supervised learning, the AI model is trained on a labeled dataset, which means that each training example is paired with an output label. The model learns to make predictions or decisions based on this labeled data. Examples include classification (e.g., identifying whether an email is spam or not) and regression (e.g., predicting house prices). The key aspect is that the model is given explicit instructions on what the output should be for each input during training.\n",
        "\n",
        "**Unsupervised Learning:** In unsupervised learning, the AI model is trained on data that does not have labeled responses. Instead, the model tries to find patterns and relationships in the data on its own. Common techniques include clustering (e.g., grouping customers based on purchasing behavior) and association (e.g., finding products that are frequently bought together). The model explores the data and looks for structures or patterns without any predefined labels or outcomes.\n",
        "\n",
        "In summary, supervised learning uses labeled data to train models to make predictions or decisions, while unsupervised learning deals with unlabeled data to identify hidden patterns and relationships.\n"
      ],
      "metadata": {
        "id": "pts6Wy-2c_mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, in summary, to get the result in text rather than JSON, you have to fetch **`response.choices[0].message.content`**"
      ],
      "metadata": {
        "id": "vM16OsmEd9Jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's add it into a function, consider this simple real-world application"
      ],
      "metadata": {
        "id": "GaNWUUTuehPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "client.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "def get_product_recommendation(customer_query):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful customer service assistant for an e-commerce store.\"},\n",
        "            {\"role\": \"user\", \"content\": customer_query}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example customer query\n",
        "customer_query = \"I'm looking for a gift for my wife. She loves cooking and reading. Any suggestions?\"\n",
        "\n",
        "recommendation = get_product_recommendation(customer_query)\n",
        "print(recommendation)\n"
      ],
      "metadata": {
        "id": "bhGXBkJyes3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Passing Images"
      ],
      "metadata": {
        "id": "3L2PIaj1fxOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, for your use-case: this is what your gpt code would potentially look like:"
      ],
      "metadata": {
        "id": "CzpqB26df2m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "client.api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "def classify_image_for_balcony(image_url):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Does this image contain a balcony?\"},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": image_url,\n",
        "                        },\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=50\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# example image URL\n",
        "image_url = \"url-to-image-of-balcony\" # I imagine this being a URL to your Storage bucket & feeding the image to the model (maybe?)\n",
        "\n",
        "classification = classify_image_for_balcony(image_url)\n",
        "print(classification)\n"
      ],
      "metadata": {
        "id": "4dgC3wZhf2Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From OpenAI's docs: Images are made available to the model in two main ways: by passing a link to the image or by passing the base64 encoded image directly in the request. Images can be passed in the user messages."
      ],
      "metadata": {
        "id": "mrpmh5-vg2z_"
      }
    }
  ]
}